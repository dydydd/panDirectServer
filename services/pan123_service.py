#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
123ç½‘ç›˜æœåŠ¡ï¼ˆç²¾ç®€ç‰ˆï¼‰
ä»…é€šè¿‡â€œè‡ªå®šä¹‰åŸŸå + æ˜ å°„è·¯å¾„ç›´å‡º + URLé‰´æƒâ€è·å–ç›´é“¾
"""

import os
import re
import time
import logging
import hashlib
import requests

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# å¦‚æœæ²¡æœ‰å¤„ç†å™¨ï¼Œæ·»åŠ æ§åˆ¶å°å¤„ç†å™¨
if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

from utils.url_auth import URLAuthManager
from utils.cache import CacheManager


class Pan123Service:
    """123ç½‘ç›˜æœåŠ¡"""
    
    def __init__(self, client, config):
        self.client = client
        self.config = config
        self.auth_manager = URLAuthManager()
        self.cache = CacheManager()
    
    def get_file_direct_link(self, file_name, mapped_path=None):
        """
        è·å–æ–‡ä»¶ç›´é“¾ï¼ˆæ”¯æŒç›´é“¾æ¨¡å¼å’Œä»£ç†æ¨¡å¼åˆ‡æ¢ï¼‰
        
        æµç¨‹ï¼š
        1. æ£€æŸ¥ä¸‹è½½æ¨¡å¼è®¾ç½®
        2. ç›´é“¾æ¨¡å¼ï¼šå°è¯•è‡ªå®šä¹‰åŸŸåç›´å‡º + URLé‰´æƒ
        3. ä»£ç†æ¨¡å¼ï¼šé€šè¿‡APIè·å–ä¸‹è½½é“¾æ¥ + ä»£ç†å¤„ç†
        
        :param file_name: æ–‡ä»¶å
        :param mapped_path: æ˜ å°„åçš„è·¯å¾„
        :return: æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å«raw_urlï¼‰
        """
        
        # å¿…é¡»æä¾›æ˜ å°„åçš„ç½‘ç›˜è·¯å¾„
        if not mapped_path:
            return None

        # æ£€æŸ¥ä¸‹è½½æ¨¡å¼è®¾ç½®
        download_mode = self.config.get('123', {}).get('download_mode', 'direct')

        # ç¬¬0æ­¥ï¼šå‘½ä¸­ç›´é“¾çŸ­æœŸç¼“å­˜ï¼ˆæŒ‰æ˜ å°„è·¯å¾„ç¼“å­˜ï¼Œé¿å…åŒåå†²çªï¼‰
        # æ³¨æ„ï¼šç›´é“¾æ¨¡å¼ï¼ˆåŸŸå+è·¯å¾„ï¼‰ä¸ç¼“å­˜ï¼Œä»£ç†æ¨¡å¼æ‰ç¼“å­˜ï¼ˆé¿å…é¢‘ç¹APIæŸ¥è¯¢ï¼‰
        # æ·»åŠ ç‰ˆæœ¬æ ‡è¯†ï¼Œç¡®ä¿ç­¾åé€»è¾‘æ›´æ–°åä¸ä½¿ç”¨æ—§ç¼“å­˜
        cache_key = f"123:{mapped_path}:{download_mode}:v2"
        
        # åªæœ‰ä»£ç†æ¨¡å¼æ‰ä½¿ç”¨ç¼“å­˜
        if download_mode == 'proxy' and self.cache.is_direct_link_valid(cache_key):
            cached = self.cache.get_direct_link(cache_key) or {}
            url = cached.get('url')
            if url:
                logger.info(f"âš¡ ä»£ç†ç›´é“¾ç¼“å­˜å‘½ä¸­: {file_name}")
                return {
                    'name': file_name,
                    'size': 0,
                    'is_dir': False,
                    'modified': '',
                    'raw_url': url,
                    'sign': '',
                    'header': {}
                }

        # æ ¹æ®ä¸‹è½½æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
        if download_mode == 'proxy':
            result = self._get_proxied_download_link(file_name, mapped_path)
            if result:
                # ç¼“å­˜ä»£ç†ä¸‹è½½é“¾æ¥
                try:
                    self.cache.set_direct_link(cache_key, result['raw_url'], expire_time=300)
                except Exception:
                    pass
            return result
        
        elif download_mode == 'direct':
            try:
                # ç¬¬ä¸€æ­¥ï¼šè‡ªå®šä¹‰åŸŸå + è·¯å¾„ç›´å‡º
                if not self._can_build_from_domain_path():
                    logger.warning("âš ï¸ æœªå¯ç”¨URLé‰´æƒæˆ–æœªé…ç½®è‡ªå®šä¹‰åŸŸåï¼Œé™çº§åˆ°ä»£ç†ä¸‹è½½")
                    return self._get_proxied_download_link(file_name, mapped_path)
                
                direct_url = self._build_url_from_domain_and_path(mapped_path)
                if not direct_url:
                    logger.warning("âš ï¸ åŸŸåç›´å‡ºå¤±è´¥ï¼Œé™çº§åˆ°ä»£ç†ä¸‹è½½")
                    return self._get_proxied_download_link(file_name, mapped_path)

                # ç¬¬äºŒæ­¥ï¼šæ·»åŠ URLé‰´æƒ
                direct_url = self._add_url_auth(direct_url)
                
                # ç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•ç›´é“¾æ˜¯å¦æœ‰æ•ˆï¼ˆå¯é€‰ï¼Œå¯èƒ½å¢åŠ å»¶è¿Ÿï¼‰
                # æ³¨é‡Šæ‰æµ‹è¯•ç¯èŠ‚ä»¥æé«˜é€Ÿåº¦ï¼Œç”±ä¸Šå±‚ç¼“å­˜æœºåˆ¶å¤„ç†
                # try:
                #     import requests
                #     test_response = requests.head(direct_url, timeout=5, allow_redirects=True)
                #     if test_response.status_code != 200:
                #         logger.warning(f"âš ï¸ ç›´é“¾æ— æ•ˆ: {test_response.status_code}ï¼Œé™çº§åˆ°ä»£ç†ä¸‹è½½")
                #         return self._get_proxied_download_link(file_name, mapped_path)
                # except Exception as e:
                #     logger.warning(f"âš ï¸ ç›´é“¾æµ‹è¯•å¤±è´¥: {e}ï¼Œé™çº§åˆ°ä»£ç†ä¸‹è½½")
                #     return self._get_proxied_download_link(file_name, mapped_path)

                # ç¬¬å››æ­¥ï¼šç›´é“¾æ¨¡å¼ä¸éœ€è¦ç¼“å­˜ï¼ˆåŸŸå+è·¯å¾„æ„å»ºå¾ˆå¿«ï¼‰
                # åªåœ¨ä¸Šå±‚Embyä»£ç†ä¸­ç¼“å­˜æœ€ç»ˆç»“æœï¼Œé¿å…é‡å¤æŸ¥è¯¢Emby API
                # æ³¨é‡Šï¼šä»£ç†æ¨¡å¼æ‰éœ€è¦ç¼“å­˜ï¼Œå› ä¸ºéœ€è¦APIæŸ¥è¯¢
                
                logger.debug(f"ğŸ”— ç›´é“¾æ¨¡å¼æˆåŠŸ: {file_name}")
                
                # è¿”å›å®Œæ•´ä¿¡æ¯
                return {
                    'name': file_name,
                    'size': 0,
                    'is_dir': False,
                    'modified': '',
                    'raw_url': direct_url,
                    'sign': '',
                    'header': {}
                }
                
            except Exception as e:
                logger.error(f"âŒ ç›´é“¾æ¨¡å¼å¼‚å¸¸: {e}ï¼Œé™çº§åˆ°ä»£ç†ä¸‹è½½")
                return self._get_proxied_download_link(file_name, mapped_path)
        
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„ä¸‹è½½æ¨¡å¼: {download_mode}")
            return None

    def _get_proxied_download_link(self, file_name, mapped_path=None, use_cache=True):
        """
        é€šè¿‡ä»£ç†æ–¹å¼è·å–ä¸‹è½½é“¾æ¥ï¼ˆæ”¯æŒç¼“å­˜æ§åˆ¶ï¼‰
        
        :param file_name: æ–‡ä»¶å
        :param mapped_path: æ˜ å°„åçš„è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        :param use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        :return: æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å«ä»£ç†åçš„ä¸‹è½½é“¾æ¥ï¼‰
        """
        try:
            # æå–æ–‡ä»¶åä¸­çš„æ–‡ä»¶IDæˆ–å…¶ä»–æ ‡è¯†
            file_id_match = re.search(r'\[(\d+)\]', file_name)
            file_id = file_id_match.group(1) if file_id_match else None

            # å¦‚æœæ²¡æœ‰æ–‡ä»¶IDï¼Œå°è¯•æœç´¢è·å–
            if not file_id:
                search_result = self.client.fs_list_new({
                    'SearchData': file_name,
                    'limit': 1
                })
                
                if search_result and search_result.get('code') == 0:
                    items = search_result.get('data', {}).get('InfoList', [])
                    if items:
                        file_id = items[0].get('FileId')

            if not file_id:
                logger.error(f"âŒ æ— æ³•è·å–æ–‡ä»¶ID: {file_name}")
                return None

            # è·å–ä¸‹è½½é“¾æ¥
            download_url = self.client.download_url({'FileID': file_id})
            
            if not download_url:
                logger.error(f"âŒ è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {file_name}")
                return None

            # é€šè¿‡ä»£ç†æ–¹å¼å¤„ç†ä¸‹è½½é“¾æ¥
            proxied_url = self._proxy_download_url(download_url)

            # å†™å…¥ç¼“å­˜ï¼ˆå¯é€‰ï¼‰
            if use_cache and mapped_path:
                cache_key = f"123_proxy:{mapped_path}"
                try:
                    self.cache.set_direct_link(cache_key, proxied_url, expire_time=300)
                except Exception:
                    pass

            return {
                'name': file_name,
                'size': 0,
                'is_dir': False,
                'modified': '',
                'raw_url': proxied_url,
                'sign': '',
                'header': {}
            }

        except Exception as e:
            logger.error(f"âŒ ä»£ç†ä¸‹è½½é“¾æ¥è·å–å¼‚å¸¸: {e}")
            return None

    def _proxy_download_url(self, download_url):
        """
        å¯¹ä¸‹è½½é“¾æ¥è¿›è¡Œä»£ç†å¤„ç† - è¿”å›å®Œæ•´çš„ä»£ç†URL
        
        :param download_url: åŸå§‹ä¸‹è½½é“¾æ¥
        :return: ä»£ç†åçš„ä¸‹è½½é“¾æ¥ï¼ˆå®Œæ•´URLï¼‰
        """
        try:
            from urllib.parse import quote
            
            # âš ï¸ å…³é”®ï¼šå¯¹åŸå§‹ä¸‹è½½é“¾æ¥è¿›è¡ŒURLç¼–ç ï¼Œé¿å…å‚æ•°æ··æ·†
            encoded_url = quote(download_url, safe='')
            
            # è·å–æœåŠ¡å™¨é…ç½®
            service_config = self.config.get('service', {})
            port = service_config.get('port', 5245)
            
            # ä¼˜å…ˆä½¿ç”¨é…ç½®çš„å¤–éƒ¨è®¿é—®åœ°å€ï¼ˆç”¨äºä»£ç†æ¨¡å¼ï¼‰
            external_url = service_config.get('external_url', '')
            
            if external_url:
                # ä½¿ç”¨é…ç½®çš„å¤–éƒ¨è®¿é—®åœ°å€ï¼ˆæ¨èï¼‰
                # ä¾‹å¦‚: http://your-server.com:5245 æˆ– https://your-domain.com
                base_url = external_url.rstrip('/')
                proxied_url = f"{base_url}/proxy/download?url={encoded_url}"
                logger.info(f"ğŸ”„ ä½¿ç”¨å¤–éƒ¨åœ°å€ç”Ÿæˆä»£ç†URL: {proxied_url[:80]}...")
            else:
                # å¦‚æœæ²¡æœ‰é…ç½®å¤–éƒ¨åœ°å€ï¼Œä½¿ç”¨è¯·æ±‚å¤´ä¸­çš„Hostï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
                try:
                    from flask import request
                    if request:
                        # ä»å½“å‰è¯·æ±‚è·å–å®¢æˆ·ç«¯è®¿é—®çš„åœ°å€
                        scheme = 'https' if request.is_secure else 'http'
                        host = request.host  # åŒ…å«ç«¯å£ï¼Œå¦‚ dy.127255.best:8096
                        # æ›¿æ¢ä¸ºæœåŠ¡ç«¯å£
                        if ':' in host:
                            host = host.split(':')[0]
                        proxied_url = f"{scheme}://{host}:{port}/proxy/download?url={encoded_url}"
                        logger.info(f"ğŸ”„ è‡ªåŠ¨æ£€æµ‹åœ°å€ç”Ÿæˆä»£ç†URL: {proxied_url[:80]}...")
                    else:
                        # å›é€€ï¼šä½¿ç”¨localhost
                        proxied_url = f"http://localhost:{port}/proxy/download?url={encoded_url}"
                        logger.warning(f"âš ï¸ æœªé…ç½®external_urlä¸”æ— æ³•è‡ªåŠ¨æ£€æµ‹ï¼Œä½¿ç”¨localhost: {proxied_url[:80]}...")
                except Exception as e:
                    # å›é€€ï¼šä½¿ç”¨localhost
                    proxied_url = f"http://localhost:{port}/proxy/download?url={encoded_url}"
                    logger.warning(f"âš ï¸ åœ°å€æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨localhost: {e}")
            
            return proxied_url

        except Exception as e:
            logger.error(f"âŒ ä»£ç†ä¸‹è½½é“¾æ¥ç”Ÿæˆå¼‚å¸¸: {e}")
            return download_url

    def _can_build_from_domain_path(self):
        """åˆ¤æ–­æ˜¯å¦å¯é€šè¿‡è‡ªå®šä¹‰åŸŸå + è·¯å¾„ç›´å‡º"""
        try:
            auth_cfg = self.config.get('123', {}).get('url_auth', {})
            domains = auth_cfg.get('custom_domains', []) or []
            return bool(auth_cfg.get('enable')) and len(domains) > 0
        except Exception:
            return False

    def _build_url_from_domain_and_path(self, mapped_path):
        """ä½¿ç”¨è‡ªå®šä¹‰åŸŸå + ç½‘ç›˜æ˜ å°„è·¯å¾„ç›´æ¥æ„é€ ç›´é“¾URL"""
        try:
            # mapped_path å½¢å¦‚: /123/dy/... éœ€å»é™¤æŒ‚è½½å‰ç¼€
            mount = (self.config.get('123', {}) or {}).get('mount_path', '/123')
            path_part = mapped_path
            if mount and mapped_path.startswith(mount):
                path_part = mapped_path[len(mount):]
            if not path_part.startswith('/'):
                path_part = '/' + path_part

            auth_cfg = self.config.get('123', {}).get('url_auth', {})
            domains = auth_cfg.get('custom_domains', []) or []
            if not domains:
                return None
            domain = domains[0].strip().rstrip('/')
            if domain.startswith('http://') or domain.startswith('https://'):
                base = domain
            else:
                base = f"https://{domain}"
            return f"{base}{path_part}"
        except Exception:
            return None
    
    def _search_file(self, file_name):
        """æœç´¢æ–‡ä»¶è·å–FileID"""
        try:
            logger.info(f"ğŸ” æœç´¢æ–‡ä»¶: {file_name}")
            
            search_result = self.client.fs_list_new({
                'SearchData': file_name,
                'limit': 20
            })
            
            if not search_result or search_result.get('code') != 0:
                logger.warning(f"âš ï¸ æœç´¢APIè¿”å›å¼‚å¸¸")
                return None, None
            
            items = search_result.get('data', {}).get('InfoList', [])
            logger.info(f"  æ‰¾åˆ° {len(items)} ä¸ªç»“æœ")
            
            # æŸ¥æ‰¾å®Œå…¨åŒ¹é…çš„æ–‡ä»¶
            for item in items:
                if item.get('FileName') == file_name and item.get('Type') == 0:
                    file_id = item['FileId']
                    logger.info(f"âœ… åŒ¹é…æ–‡ä»¶: FileId={file_id}")
                    return file_id, item
            
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„æ–‡ä»¶")
            return None, None
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¼‚å¸¸: {e}")
            return None, None
    
    # å·²ç§»é™¤ï¼šOpenAPI ä¸ download_url è·å–ç›´é“¾çš„å®ç°
    
    def _add_url_auth(self, url):
        """æ·»åŠ URLé‰´æƒç­¾å"""
        if not url:
            return url
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é‰´æƒ
        auth_config = self.config.get('123', {}).get('url_auth', {})
        if not auth_config.get('enable'):
            logger.info(f"  URLé‰´æƒæœªå¯ç”¨")
            return url
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‰´æƒï¼ˆæ”¯æŒè‡ªå®šä¹‰åŸŸåï¼‰
        custom_domains = auth_config.get('custom_domains', [])
        if not self.auth_manager.is_123pan_url(url, custom_domains):
            logger.info(f"  é123ç½‘ç›˜URLï¼Œè·³è¿‡é‰´æƒ")
            return url
        
        # è·å–é‰´æƒå‚æ•°
        secret_key = auth_config.get('secret_key')
        uid = auth_config.get('uid')
        expire_time = auth_config.get('expire_time', 3600)
        
        if not (secret_key and uid):
            logger.warning(f"âš ï¸ URLé‰´æƒå·²å¯ç”¨ä½†ç¼ºå°‘é…ç½®")
            return url
        
        # æ·»åŠ ç­¾å
        logger.debug(f"ğŸ” æ·»åŠ URLé‰´æƒç­¾å...")
        auth_url = self.auth_manager.add_auth_to_url(url, secret_key, uid, expire_time)
        
        return auth_url
    
    # å·²ç§»é™¤ï¼šè·å– OpenAPI access_token çš„é€»è¾‘

