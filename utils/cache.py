#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import time
import logging
from pathlib import Path
from database.database import get_db_manager

logger = logging.getLogger(__name__)

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - SQLite ä¼˜åŒ–ç‰ˆæœ¬"""

    def __init__(self):
        # è·å–æ•°æ®åº“ç®¡ç†å™¨
        self.db = get_db_manager()
        
        # å…¼å®¹æ€§ï¼šä»æ—§çš„JSONæ–‡ä»¶è¿ç§»æ•°æ®
        self.PATH_CACHE_FILE = Path('config/path_cache.json')
        self._migrate_from_json()

    def _migrate_from_json(self):
        """ä»æ—§çš„JSONæ–‡ä»¶è¿ç§»æ•°æ®åˆ°SQLite"""
        try:
            if self.PATH_CACHE_FILE.exists():
                logger.info("ğŸ”„ å‘ç°æ—§çš„è·¯å¾„ç¼“å­˜æ–‡ä»¶ï¼Œå¼€å§‹è¿ç§»åˆ°SQLite...")
                with open(self.PATH_CACHE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        migrated = 0
                        for path, file_id in data.items():
                            if self.db.set_path_id(str(path), str(file_id)):
                                migrated += 1
                        
                        logger.info(f"âœ… è¿ç§»å®Œæˆ: {migrated} æ¡è·¯å¾„ç¼“å­˜")
                        
                        # å¤‡ä»½å¹¶åˆ é™¤æ—§æ–‡ä»¶
                        backup_file = self.PATH_CACHE_FILE.with_suffix('.json.bak')
                        self.PATH_CACHE_FILE.rename(backup_file)
                        logger.info(f"ğŸ“¦ æ—§æ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ è¿ç§»è·¯å¾„ç¼“å­˜å¤±è´¥: {e}")

    def get_direct_link(self, path):
        """è·å–ç¼“å­˜çš„ç›´é“¾"""
        cached = self.db.get_direct_link(path)
        if cached:
            return {
                'url': cached['url'],
                'expire': cached['expire_time']
            }
        return None

    def set_direct_link(self, path, url, expire_time=3600):
        """è®¾ç½®ç›´é“¾ç¼“å­˜"""
        success = self.db.set_direct_link(path, url, expire_time)
        if success:
            logger.debug(f"âœ… ç›´é“¾ç¼“å­˜å·²è®¾ç½®: {path}")
        return success

    def is_direct_link_valid(self, path):
        """æ£€æŸ¥ç›´é“¾ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        cached = self.db.get_direct_link(path)
        return cached is not None

    def get_path_id(self, path):
        """è·å–è·¯å¾„IDç¼“å­˜"""
        return self.db.get_path_id(path)

    def set_path_id(self, path, file_id):
        """è®¾ç½®è·¯å¾„IDç¼“å­˜"""
        success = self.db.set_path_id(path, file_id)
        if success:
            logger.debug(f"âœ… è·¯å¾„IDç¼“å­˜å·²è®¾ç½®: {path} -> {file_id}")
        return success
    

    def clear_all_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        result = self.db.clear_all_cache()
        
        # æ¸…ç†è¿‡æœŸç›´é“¾ç¼“å­˜
        expired_count = self.db.clear_expired_direct_links()
        if expired_count > 0:
            logger.info(f"ğŸ§¹ å·²æ¸…ç† {expired_count} æ¡è¿‡æœŸç›´é“¾")
        
        logger.info(f"âœ… ç¼“å­˜å·²æ¸…é™¤: {result}")
        return {'cleared': result}

    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        stats = self.db.get_cache_stats()
        
        # ç®€åŒ–è¿”å›æ ¼å¼ä»¥å…¼å®¹åŸæœ‰ä»£ç 
        return {
            'direct_links': stats.get('direct_links', {}).get('valid_count', 0),
            'path_ids': stats.get('path_ids', {}).get('total_count', 0),
            'detailed_stats': stats  # æä¾›è¯¦ç»†ç»Ÿè®¡
        }